# biweekly-report-3-bema8444

#Addition_NMT
In this notebook I explore how to apply the same sequence to sequence structure we have discussed before to things other than spoken language. I treat addition and the resulting answers as their own languages 
and train a model to translate from a string "xxx+xxx" to an answer "xxx". I found this idea very interesting because I hadn't thought about other applications of NMT like this.

#French_English
In this notebook I make a fairly simple French to English translation model using a character level recurrent sequence to sequence structure.

#NMT_with_Attention
In this notebook I build off of an already well documented notebook of NMT with attention from Spanish to English. I look at the attention plots and discuss how we can use these to 
see strengths and short comings of this model
