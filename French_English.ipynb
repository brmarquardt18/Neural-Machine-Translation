{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "In this notebook I will be exploring a character level recurrent sequence to sequence model. I will be using it to translate fairly short english sentences to french sentences.  Much of the code to build the model I found from the link https://keras.io/examples/nlp/lstm_seq2seq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data used is from http://www.manythings.org/anki/ and is of the form of an English sentence corresponding with a French sentence along with the place from which this relationship was found, which we will not care about moving forwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  \n",
    "epochs = 100  \n",
    "latent_dim = 256 \n",
    "num_samples = 10000  \n",
    "\n",
    "data_path = \"C://Users//benma//Desktop//5720 pics//fra.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, I will first need to vectorize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "    # \"tab\" indicates the start of the sequence\n",
    "    # \\n indicates the end of the sequence\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to show what the form of the data is, I will do a very limited amount of data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 93\n",
      "Max sequence length for inputs: 15\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of samples:\", len(input_texts))\n",
    "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)',\n",
       " 'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)',\n",
       " 'Go.\\tBouge !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)',\n",
       " 'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)',\n",
       " 'Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)',\n",
       " 'Run!\\tCours\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)',\n",
       " 'Run!\\tCourez\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)',\n",
       " 'Run!\\tPrenez vos jambes à vos cous !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077449 (sacredceltic)',\n",
       " 'Run!\\tFile !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077454 (sacredceltic)',\n",
       " 'Run!\\tFilez !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #2077455 (sacredceltic)',\n",
       " 'Run!\\tCours !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #4580779 (franlexcois)',\n",
       " 'Run!\\tFuyez !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #7957917 (Micsmithel)',\n",
       " 'Run!\\tFuyons !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #7957918 (Micsmithel)',\n",
       " 'Run.\\tCours\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #906331 (sacredceltic)',\n",
       " 'Run.\\tCourez\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #906332 (sacredceltic)',\n",
       " 'Run.\\tPrenez vos jambes à vos cous !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #2077449 (sacredceltic)',\n",
       " 'Run.\\tFile !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #2077454 (sacredceltic)',\n",
       " 'Run.\\tFilez !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #2077455 (sacredceltic)',\n",
       " 'Run.\\tCours !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #4580779 (franlexcois)',\n",
       " 'Run.\\tFuyez !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #7957917 (Micsmithel)',\n",
       " 'Run.\\tFuyons !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4008918 (JSakuragi) & #7957918 (Micsmithel)',\n",
       " 'Who?\\tQui ?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #4366796 (gillux)',\n",
       " 'Wow!\\tÇa alors\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #374631 (zmoo)',\n",
       " 'Fire!\\tAu feu !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #4627939 (sacredceltic)',\n",
       " \"Help!\\tÀ l'aide\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #128430 (sysko)\",\n",
       " 'Jump!\\tSaute.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1102981 (jamessilver) & #2416938 (Micsmithel)',\n",
       " 'Jump.\\tSaute.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #2416938 (Micsmithel)',\n",
       " 'Stop!\\tÇa suffit\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #516030 (Goofy)',\n",
       " 'Stop!\\tStop\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #626567 (U2FS)',\n",
       " 'Stop!\\tArrête-toi !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #448320 (FeuDRenais) & #1157663 (sacredceltic)',\n",
       " 'Wait!\\tAttends !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #1157682 (sacredceltic)',\n",
       " 'Wait!\\tAttendez !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #1157684 (sacredceltic)',\n",
       " 'Wait!\\tAttendez.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1744314 (belgavox) & #7693749 (Micsmithel)',\n",
       " 'Wait.\\tAttends !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #1157682 (sacredceltic)',\n",
       " 'Wait.\\tAttendez !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #1157684 (sacredceltic)',\n",
       " 'Wait.\\tAttends.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #5137155 (gege_veggie)',\n",
       " 'Wait.\\tAttendez.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3048304 (camilozeta) & #7693749 (Micsmithel)',\n",
       " 'Begin.\\tCommencez.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #6102432 (mailohilohi) & #7956660 (Micsmithel)',\n",
       " 'Begin.\\tCommence.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #6102432 (mailohilohi) & #7957931 (Micsmithel)',\n",
       " 'Go on.\\tPoursuis.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #588132 (sacredceltic)',\n",
       " 'Go on.\\tContinuez.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #6463161 (Aiji)',\n",
       " 'Go on.\\tPoursuivez.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2230774 (CK) & #6463162 (Aiji)',\n",
       " 'Hello!\\tBonjour !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #373330 (CK) & #373345 (Aiji)',\n",
       " 'Hello!\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #373330 (CK) & #509819 (Aiji)',\n",
       " 'I see.\\tJe comprends.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2111796 (CK) & #1511205 (Hikari)',\n",
       " 'I see.\\tAha.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2111796 (CK) & #8304768 (Micsmithel)',\n",
       " \"I try.\\tJ'essaye.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #20776 (CK) & #1133630 (nimfeo)\",\n",
       " \"I won!\\tJ'ai gagné !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2005192 (CK) & #2005252 (sacredceltic)\",\n",
       " \"I won!\\tJe l'ai emporté !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2005192 (CK) & #2005253 (sacredceltic)\",\n",
       " 'I won.\\tJ’ai gagné.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #5828608 (CK) & #7700885 (sacredceltic)']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the first lines are the shortest sentences, which we will be focussing on more than the longer ones. Also notice how many sentences occur a few times. The reason for this is simple, there are often multiple translations for the same meaning of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I used to watch this anime a lot when I was a kid, but I can't quite remember what happened to the hero in the final episode.\\tJ'avais l'habitude de beaucoup regarder ce dessin animé quand j'étais enfant, mais je ne peux plus trop me rappeler ce qui est arrivé au héros dans l'ultime épisode.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1108355 (CK) & #1108843 (sacredceltic)\",\n",
       " 'In the same amount of time it would take me to correct all the mistakes in your report, I could write a better report myself.\\tDans le même laps de temps que ça me prendrait de corriger toutes les erreurs de votre rapport, je pourrais écrire un meilleur rapport moi-même.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3107051 (CK) & #8302106 (Aiji)',\n",
       " 'The English language is undoubtedly the easiest and at the same time the most efficient means of international communication.\\tLa langue anglaise est indubitablement la plus facile et en même temps le moyen de communication internationale le plus efficace.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #571143 (CK) & #774168 (U2FS)',\n",
       " \"I thought I had paid the monthly fee, but I received a phone call from the school saying that the bill still needs to be paid.\\tJe pensais avoir payé les frais mensuels, mais j'ai reçu un coup de téléphone de l'école disant que la facture devait encore être payée.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1529635 (erikspen) & #8302052 (Aiji)\",\n",
       " 'Instead of giving each other Christmas presents this year, we donated the amount we would have spent on presents to a charity.\\tCette année, au lieu de nous offrir mutuellement des cadeaux de Noël, nous avons donné à une organisation caritative le montant que nous aurions dépensé en cadeaux.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #5681156 (CK) & #9520443 (Micsmithel)',\n",
       " 'A great relationship is based on two main principles. First, appreciate your similarities and second, respect your differences.\\tUne bonne relation est basée sur deux principes importants. Premièrement, appréciez vos similitudes, et deuxièmement, respectez vos différences.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2840508 (patgfisher) & #8328955 (Aiji)',\n",
       " \"According to the contract you may take three days of bereavement leave for your uncle's funeral, but only one for your nephew's.\\tConformément au contrat, vous pouvez prendre trois jours de congé de deuil pour les funérailles de votre oncle, mais un seul pour celles de votre neveu.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2158345 (Dreamk33) & #2158351 (Dreamk33)\",\n",
       " \"According to the contract you may take three days of bereavement leave for your uncle's funeral, but only one for your nephew's.\\tConformément aux closes du contrat, vous pouvez prendre trois jours de congé de deuil pour les funérailles de votre oncle, mais un seul pour celles de votre neveu.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2158345 (Dreamk33) & #2158352 (Dreamk33)\",\n",
       " \"According to the contract you may take three days of bereavement leave for your uncle's funeral, but only one for your nephew's.\\tConformément au contrat, vous pouvez prendre trois jours de congé de décès pour les funérailles de votre oncle, mais un seul pour celles de votre neveu.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2158345 (Dreamk33) & #2158357 (Dreamk33)\",\n",
       " \"Food prices are at their highest level since the United Nations Food and Agriculture Organization began keeping records in 1990.\\tLes prix de l'alimentation sont à leur plus haut niveau depuis que l'Organisation des Nations Unies pour l’alimentation et l’agriculture a commencé à les enregistrer en mille-neuf-cent-quatre-vingt-dix.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1141301 (Source_VOA) & #1141383 (sacredceltic)\",\n",
       " \"If one has the right to live, then one should also have the right to die. If not, then living is not a right, but an obligation.\\tSi quelqu'un détient le droit de vivre, alors il devrait également détenir celui de mourir. Sinon, vivre n'est alors pas un droit mais une obligation.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2114902 (CK) & #2119232 (sacredceltic)\",\n",
       " \"It was bad enough that he usually came to work late, but coming in drunk was the last straw, and I'm going to have to let him go.\\tC'était suffisamment grave qu'il ait l'habitude d'arriver en retard au travail, mais qu'il arrive soûl est un comble, et je vais devoir m'en séparer.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #40879 (CM) & #347605 (Barbiche0)\",\n",
       " \"The teacher supervising the playground became concerned when she saw a man talking to some of the children over the school fence.\\tL'institutrice chargée de surveiller la cour s'inquiéta lorsqu'elle vit un homme parler à des enfants par-dessus la grille de l'école.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3369104 (patgfisher) & #3422736 (sacredceltic)\",\n",
       " \"Cities and provinces along the Yangtze River in central China are grappling with the country's worst drought in more than 50 years.\\tLes villes et les provinces le long du fleuve Yangtsé, au centre de la Chine, sont aux prises avec la pire sécheresse que le pays ait connu depuis plus de cinquante ans.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #912382 (Source_VOA) & #1591746 (sacredceltic)\",\n",
       " \"That proposal may be a way to kill two birds with one stone, but we also have to be careful not to get greedy and spoil everything.\\tCette proposition pourrait faire d'une pierre deux coups, mais nous devons aussi faire attention à ne pas devenir gourmands et ainsi tout gâcher.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #44947 (CK) & #415747 (kilwann)\",\n",
       " \"A committee is a group of people who individually can do nothing, but who, as a group, can meet and decide that nothing can be done.\\tUn comité est un groupe de gens qui ne peuvent rien faire individuellement mais qui peuvent tenir des réunions en tant que groupe et parvenir à la décision qu'on ne peut rien faire.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1582370 (Biga) & #1582396 (sacredceltic)\",\n",
       " \"My breakfast usually consists of coffee with milk, a piece of bread and jam, a small banana, a piece of orange and some dried plums.\\tMon petit-déjeuner se compose généralement de café au lait, d'un morceau de pain avec de la confiture, d'une petite banane, d'un morceau d'orange et de prunes séchées.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2871753 (patgfisher) & #8302102 (Aiji)\",\n",
       " \"One of the best ways to help us is to translate from a foreign language you know into your own native language or strongest language.\\tL'une des meilleures manières de nous aider est de traduire d'une langue étrangère que vous connaissez vers votre propre langue natale, ou la plus forte de vos langues.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3672878 (CK) & #3673151 (sacredceltic)\",\n",
       " \"Since it will be cold soon, it might be nice to enjoy doing something outdoors the final few warm days we have before winter sets in.\\tPuisqu'il fera bientôt froid, ça serait chouette de profiter des quelques derniers jours chauds dont nous disposons pour faire quelque chose à l'extérieur, avant que l'hiver ne s'installe.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1988007 (CK) & #1988311 (sacredceltic)\",\n",
       " \"People tend to only compliment you on your language ability when it's apparent that you still don't quite sound like a native speaker.\\tLes gens ont tendance à vous complimenter sur vos compétences linguistiques seulement lorsqu’il est évident que votre prononciation ne correspond pas tout à fait à celle d’un autochtone.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3567279 (CK) & #8358639 (sacredceltic)\",\n",
       " \"A man who has never gone to school may steal from a freight car, but if he has a university education, he may steal the whole railroad.\\tUn homme qui n'a jamais été à l'école peut voler d'un wagon, mais s'il dispose d'un diplôme, il peut voler toute la ligne de chemin de fer.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #21495 (CM) & #1222972 (sacredceltic)\",\n",
       " \"What is old age? First you forget names, then you forget faces, then you forget to pull your zipper up, then you forget to pull it down.\\tQu'est l'âge ? D'abord on oublie les noms, et puis on oublie les visages, puis on oublie de remonter sa braguette, et puis on oublie de la descendre.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3645429 (karloelkebekio) & #3649907 (sacredceltic)\",\n",
       " \"What is old age? First you forget names, then you forget faces, then you forget to pull your zipper up, then you forget to pull it down.\\tCe qu'est l'âge ? D'abord on oublie les noms, et puis on oublie les visages, puis on oublie de remonter sa braguette, et puis on oublie de la descendre.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3645429 (karloelkebekio) & #3650597 (sacredceltic)\",\n",
       " \"He and I have a near-telepathic understanding of each other. No sooner does one of us say something than the other is already responding.\\tLui et moi avons une compréhension quasi-télépathique de chacun. Aussitôt que l'un de nous dit quelque chose, l'autre est déjà en train de répondre.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #284423 (CM) & #130052 (dominiko)\",\n",
       " \"Although rainforests make up only two percent of the earth's surface, over half the world's wild plant, animal and insect species live there.\\tBien que les forêts tropicales ne couvrent que 2% de la surface de la terre, plus de la moitié des espèces animales, végétales et des insectes y vivent.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #26666 (Zifre) & #9886 (Dreamk33)\",\n",
       " \"She has a boyfriend she's been going out with since high school, but she feels their relationship has stagnated, so she's become dissatisfied.\\tElle a un copain avec qui elle sort depuis le lycée, mais elle a le sentiment que leur relation stagne, alors elle est mécontente.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1334078 (CM) & #4957580 (celineamb)\",\n",
       " \"If you take a child outside and point at the moon, the child will look at the moon. If you do the same with a dog, it will look at your finger.\\tSi vous emmenez un enfant dehors et pointez la lune, l'enfant regardera la lune. Si vous faites la même chose avec un chien, le chien regardera le doigt.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3693622 (patgfisher) & #8293160 (Aiji)\",\n",
       " \"If you translate from your second language into your own native language, rather than the other way around, you're less likely to make mistakes.\\tSi vous traduisez de votre seconde langue dans votre propre langue maternelle, plutôt que dans l'autre sens, il y a moins de chances que vous commettiez des fautes.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1230823 (CK) & #2084056 (sacredceltic)\",\n",
       " \"I love trying out new things, so I always buy products as soon as they hit the store shelves. Of course, half the time I end up wishing I hadn't.\\tJ'adore essayer de nouvelles choses, alors j'achète toujours des produits dès qu'ils sont en rayons. Bien sûr, la moitié du temps, je finis par souhaiter ne pas l'avoir fait.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #249549 (CM) & #5192034 (sacredceltic)\",\n",
       " \"A good theory is characterized by the fact that it makes a number of predictions that could in principle be disproved or falsified by observation.\\tUne bonne théorie se caractérise par le fait de faire une série de prédictions qui, en principe, pourraient être réfutées ou mises en défaut par l'observation.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #30000 (CM) & #657308 (qdii)\",\n",
       " 'An Earth-like planet, which is believed to have conditions which would support life as we know it, has been discovered 500 light years from earth.\\tUne planète semblable à la Terre, qui aurait des conditions favorables à la vie telle que nous la connaissons, a été découverte à 500 années-lumière de la Terre.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3196883 (patgfisher) & #8302064 (Aiji)',\n",
       " \"The more time you spend speaking a foreign language, the better you get at guessing what non-native speakers are trying to say in your own language.\\tPlus l'on passe de temps à parler une langue étrangère, plus l'on s'améliore à devenir ce qu'un non-natif essaie de dire dans sa propre langue.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2278815 (CK) & #2278820 (sysko)\",\n",
       " \"The enquiry concluded that, despite his denials, the chief executive would have had to have known about the illegal practices occurring in the company.\\tL'enquête conclut qu'en dépit de ses dénégations, le directeur général aurait eu connaissance des pratiques illégales, en cours dans l'entreprise.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #4205323 (patgfisher) & #4215281 (sacredceltic)\",\n",
       " \"Roger Miller's father died when he was only one year old and his mother became sick soon after, so he was sent to live with his uncle in Erick, Oklahoma.\\tLe père de Roger Miller est décédé lorsqu'il avait un an et sa mère est tombée malade peu après. Il a donc été envoyé vivre avec son oncle à Erick, dans l'Oklahoma.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #552247 (American) & #8293376 (Aiji)\",\n",
       " \"You may not learn to speak as well as a native speaker, but you should be able to speak well enough that native speakers will understand what you have to say.\\tPeut-être n'apprendrez-vous pas à parler comme un locuteur natif, mais vous devriez être en mesure de parler suffisamment bien pour que les natifs comprennent ce que vous avez à dire.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #954773 (CK) & #960150 (sacredceltic)\",\n",
       " \"And the good news is that today the economy is growing again. Wages, incomes, home values and retirement accounts are all rising again. Poverty is falling again.\\tEt la bonne nouvelle est qu'aujourd'hui l'économie se développe à nouveau. Salaire, revenus, valeurs immobilières et comptes de retraites sont tous à la hausse. La pauvreté retombe.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762722 (CO) & #5764653 (Thomz)\",\n",
       " \"E-cigarettes are being promoted as a healthy alternative to tobacco cigarettes, but health authorities are concerned about the long-term health effects on users.\\tLa cigarette électronique est mise en avant comme une saine alternative aux cigarettes, mais les autorités sanitaires s'inquiètent des effets à long terme sur la santé des consommateurs.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #3383721 (patgfisher) & #3422726 (sacredceltic)\",\n",
       " \"It's still too hard to find a job. And even if you have a job, chances are you're having a tougher time paying the rising costs of everything from groceries to gas.\\tC'est encore trop difficile de trouver un emploi. Et même quand on en a un, il y a des chances qu'on ait davantage de difficultés à payer le coût de tout, de l'épicerie au gaz.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #897909 (CO) & #1407043 (sacredceltic)\",\n",
       " \"Even at the end of the nineteenth century, sailors in the British Navy were not permitted to use knives and forks because using them was considered a sign of weakness.\\tMême à la fin du dix-neuvième siècle, les marins de la marine britannique n'étaient pas autorisés à utiliser des couteaux et des fourchettes parce que c'était considéré comme un signe de faiblesse.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #73247 (CM) & #9995 (dominiko)\",\n",
       " \"Five tremors in excess of magnitude 5.0 on the Richter scale have shaken Japan just this week, but scientists are warning that the largest expected aftershock has yet to hit.\\tCinq secousses dépassant la magnitude cinq sur l'échelle de Richter ont secoué le Japon précisément cette semaine, mais les scientifiques avertissent que la plus grande réplique est encore à venir.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #912384 (Source_VOA) & #1591739 (sacredceltic)\",\n",
       " \"No matter how much you try to convince people that chocolate is vanilla, it'll still be chocolate, even though you may manage to convince yourself and a few others that it's vanilla.\\tPeu importe le temps que tu passeras à essayer de convaincre les gens que le chocolat est de la vanille, ça restera toujours du chocolat, même si tu réussis à convaincre toi et quelques autres que c'est de la vanille.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #939787 (CK) & #939868 (Quazel)\",\n",
       " \"A child who is a native speaker usually knows many things about his or her language that a non-native speaker who has been studying for years still does not know and perhaps will never know.\\tUn enfant qui est un locuteur natif connaît habituellement de nombreuses choses sur son langage qu'un locuteur non-natif qui a étudié pendant des années ignore encore et peut-être ne saura jamais.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #953070 (CK) & #1294574 (sacredceltic)\",\n",
       " \"There are four main causes of alcohol-related death. Injury from car accidents or violence is one. Diseases like cirrhosis of the liver, cancer, heart and blood system diseases are the others.\\tIl y a quatre causes principales de décès liés à l'alcool. Les blessures dans les accidents automobiles ou la violence en est une. Les maladies comme la cirrhose, le cancer, les maladies cardio-vasculaires en sont les autres.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1141314 (Source_VOA) & #1141347 (sacredceltic)\",\n",
       " \"We need to uphold laws against discrimination — in hiring, and in housing, and in education, and in the criminal justice system. That is what our Constitution and our highest ideals require.\\tNous devons faire respecter les lois contre la discrimination à l'embauche, au logement, à l'éducation et dans la justice pénale. C'est ce que notre Constitution et nos plus hauts idéaux exigent.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #5762728 (CO) & #5764670 (Thomz)\",\n",
       " '\"Top-down economics never works,\" said Obama. \"The country does not succeed when just those at the very top are doing well. We succeed when the middle class gets bigger, when it feels greater security.\"\\t« L\\'économie en partant du haut vers le bas, ça ne marche jamais, » a dit Obama. « Le pays ne réussit pas lorsque seulement ceux qui sont au sommet s\\'en sortent bien. Nous réussissons lorsque la classe moyenne s\\'élargit, lorsqu\\'elle se sent davantage en sécurité. »\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1863010 (Source_VOA) & #2084059 (sacredceltic)',\n",
       " \"A carbon footprint is the amount of carbon dioxide pollution that we produce as a result of our activities. Some people try to reduce their carbon footprint because they are concerned about climate change.\\tUne empreinte carbone est la somme de pollution au dioxyde de carbone que nous produisons par nos activités. Certaines personnes essaient de réduire leur empreinte carbone parce qu'elles sont inquiètes du changement climatique.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1141316 (Source_VOA) & #1141339 (sacredceltic)\",\n",
       " \"Death is something that we're often discouraged to talk about or even think about, but I've realized that preparing for death is one of the most empowering things you can do. Thinking about death clarifies your life.\\tLa mort est une chose qu'on nous décourage souvent de discuter ou même de penser mais j'ai pris conscience que se préparer à la mort est l'une des choses que nous puissions faire qui nous investit le plus de responsabilité. Réfléchir à la mort clarifie notre vie.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1969892 (davearms) & #1969962 (sacredceltic)\",\n",
       " \"Since there are usually multiple websites on any given topic, I usually just click the back button when I arrive on any webpage that has pop-up advertising. I just go to the next page found by Google and hope for something less irritating.\\tPuisqu'il y a de multiples sites web sur chaque sujet, je clique d'habitude sur le bouton retour arrière lorsque j'atterris sur n'importe quelle page qui contient des publicités surgissantes. Je me rends juste sur la prochaine page proposée par Google et espère tomber sur quelque chose de moins irritant.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #954270 (CK) & #957693 (sacredceltic)\",\n",
       " \"If someone who doesn't know your background says that you sound like a native speaker, it means they probably noticed something about your speaking that made them realize you weren't a native speaker. In other words, you don't really sound like a native speaker.\\tSi quelqu'un qui ne connaît pas vos antécédents dit que vous parlez comme un locuteur natif, cela veut dire qu'il a probablement remarqué quelque chose à propos de votre élocution qui lui a fait prendre conscience que vous n'êtes pas un locuteur natif. En d'autres termes, vous ne parlez pas vraiment comme un locuteur natif.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #953936 (CK) & #955961 (sacredceltic)\",\n",
       " '']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 50 sentences are clearly much longer and more complicated. Thus, there are not really repeating sentences. Since this is a much simpler model and we will not be training it extensively, I will not be focussing on these more complicated, longer sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding \n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to build the model. For this, we will use an encoder LSTM to turn input sequences into an array of 2 states. We will keep the last LSTM state and discard the outputs. We will use a decoder LSTM that is trained to turn the target sequence into the same sequence but offset by a timestep. The reason for this is because we are teaching the decoder to make targets[i+1] given targets[i] conditioned on the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train the model. The \"tutorial\" from which I got much of this code was using the optimizer of RMSprop but I decided to change this to the Adam optimizer since this has been what I have used in the past and I dont see a good reason why not to use Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"Adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=30,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "# Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for running inference, we will encode the input and get the intial decoder state. After this, we run one step of the decoder with this state and a \"start\" token out front. The output of this is the next target token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "125/125 [==============================] - 28s 208ms/step - loss: 0.0437 - accuracy: 0.9847 - val_loss: 0.7655 - val_accuracy: 0.8701\n",
      "Epoch 2/30\n",
      "125/125 [==============================] - 25s 202ms/step - loss: 0.0393 - accuracy: 0.9860 - val_loss: 0.7658 - val_accuracy: 0.8699\n",
      "Epoch 3/30\n",
      "125/125 [==============================] - 25s 201ms/step - loss: 0.0385 - accuracy: 0.9863 - val_loss: 0.7764 - val_accuracy: 0.8695\n",
      "Epoch 4/30\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.7763 - val_accuracy: 0.8696\n",
      "Epoch 5/30\n",
      "125/125 [==============================] - 27s 220ms/step - loss: 0.0374 - accuracy: 0.9866 - val_loss: 0.7806 - val_accuracy: 0.8696\n",
      "Epoch 6/30\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.0364 - accuracy: 0.9871 - val_loss: 0.7753 - val_accuracy: 0.8692\n",
      "Epoch 7/30\n",
      "125/125 [==============================] - 27s 220ms/step - loss: 0.0378 - accuracy: 0.9864 - val_loss: 0.7865 - val_accuracy: 0.8700\n",
      "Epoch 8/30\n",
      "125/125 [==============================] - 29s 232ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.7847 - val_accuracy: 0.8695\n",
      "Epoch 9/30\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.0366 - accuracy: 0.9866 - val_loss: 0.7870 - val_accuracy: 0.8699\n",
      "Epoch 10/30\n",
      "125/125 [==============================] - 27s 215ms/step - loss: 0.0358 - accuracy: 0.9870 - val_loss: 0.7910 - val_accuracy: 0.8692\n",
      "Epoch 11/30\n",
      "125/125 [==============================] - 27s 216ms/step - loss: 0.0351 - accuracy: 0.9870 - val_loss: 0.7910 - val_accuracy: 0.8698\n",
      "Epoch 12/30\n",
      "125/125 [==============================] - 27s 214ms/step - loss: 0.0351 - accuracy: 0.9873 - val_loss: 0.7916 - val_accuracy: 0.8692\n",
      "Epoch 13/30\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 0.0351 - accuracy: 0.9875 - val_loss: 0.7941 - val_accuracy: 0.8697\n",
      "Epoch 14/30\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 0.0339 - accuracy: 0.9875 - val_loss: 0.8012 - val_accuracy: 0.8694\n",
      "Epoch 15/30\n",
      "125/125 [==============================] - 27s 212ms/step - loss: 0.0341 - accuracy: 0.9873 - val_loss: 0.8003 - val_accuracy: 0.8698\n",
      "Epoch 16/30\n",
      "125/125 [==============================] - 27s 215ms/step - loss: 0.0340 - accuracy: 0.9872 - val_loss: 0.8006 - val_accuracy: 0.8695\n",
      "Epoch 17/30\n",
      "125/125 [==============================] - 27s 213ms/step - loss: 0.0332 - accuracy: 0.9877 - val_loss: 0.8024 - val_accuracy: 0.8690\n",
      "Epoch 18/30\n",
      "125/125 [==============================] - 27s 214ms/step - loss: 0.0324 - accuracy: 0.9878 - val_loss: 0.8135 - val_accuracy: 0.8690\n",
      "Epoch 19/30\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.0337 - accuracy: 0.9873 - val_loss: 0.8058 - val_accuracy: 0.8698\n",
      "Epoch 20/30\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.0333 - accuracy: 0.9877 - val_loss: 0.8127 - val_accuracy: 0.8686\n",
      "Epoch 21/30\n",
      "125/125 [==============================] - 29s 233ms/step - loss: 0.0325 - accuracy: 0.9879 - val_loss: 0.8176 - val_accuracy: 0.8691\n",
      "Epoch 22/30\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.0318 - accuracy: 0.9880 - val_loss: 0.8134 - val_accuracy: 0.8699\n",
      "Epoch 23/30\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.0326 - accuracy: 0.9877 - val_loss: 0.8141 - val_accuracy: 0.8695\n",
      "Epoch 24/30\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.0321 - accuracy: 0.9879 - val_loss: 0.8182 - val_accuracy: 0.8691\n",
      "Epoch 25/30\n",
      "125/125 [==============================] - 28s 221ms/step - loss: 0.0345 - accuracy: 0.9870 - val_loss: 0.8230 - val_accuracy: 0.8692\n",
      "Epoch 26/30\n",
      "125/125 [==============================] - 28s 222ms/step - loss: 0.0337 - accuracy: 0.9870 - val_loss: 0.8168 - val_accuracy: 0.8691\n",
      "Epoch 27/30\n",
      "125/125 [==============================] - 29s 229ms/step - loss: 0.0313 - accuracy: 0.9880 - val_loss: 0.8238 - val_accuracy: 0.8699\n",
      "Epoch 28/30\n",
      "125/125 [==============================] - 28s 224ms/step - loss: 0.0315 - accuracy: 0.9880 - val_loss: 0.8210 - val_accuracy: 0.8696\n",
      "Epoch 29/30\n",
      "125/125 [==============================] - 28s 226ms/step - loss: 0.0301 - accuracy: 0.9883 - val_loss: 0.8324 - val_accuracy: 0.8689\n",
      "Epoch 30/30\n",
      "125/125 [==============================] - 29s 230ms/step - loss: 0.0299 - accuracy: 0.9883 - val_loss: 0.8294 - val_accuracy: 0.8693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_16_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_16_layer_call_and_return_conditional_losses, lstm_cell_16_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_16_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nYou can now generate decoded sentences as such:\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"s2s\")\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now test the model that we have made. First, we create a decode sequence function that allows us to decode the sequence returned from the encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fun part now is that we can see how well the model works by testing it on real sentences. I will first look at the first chunk of sentences which are largely one or two word phrases/sentences. I also add a check to only print out sentences that we have not seen previously because while there may be multiple translations from the origin sentence, our model will only provide on. As such, to avoid the output being repetitive, we only want to see each sentence once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: Hi.\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Filez !\n",
      "\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Qui ?\n",
      "\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Ça alors !\n",
      "\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Au feu !\n",
      "\n",
      "Input sentence: Help!\n",
      "Decoded sentence: À l'aide !\n",
      "\n",
      "Input sentence: Jump!\n",
      "Decoded sentence: Saute.\n",
      "\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Ça suffit !\n",
      "\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "Input sentence: Begin.\n",
      "Decoded sentence: Commencez.\n",
      "\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuis.\n",
      "\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je comprends.\n",
      "\n",
      "Input sentence: I try.\n",
      "Decoded sentence: J'essaye.\n",
      "\n",
      "Input sentence: I won!\n",
      "Decoded sentence: Je l'ai emporté !\n",
      "\n",
      "Input sentence: I won.\n",
      "Decoded sentence: J’ai gagné.\n",
      "\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Oh non !\n",
      "\n",
      "Input sentence: Relax.\n",
      "Decoded sentence: Détends-toi.\n",
      "\n",
      "Input sentence: Smile.\n",
      "Decoded sentence: Souriez !\n",
      "\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaquez !\n",
      "\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "Input sentence: Eat it.\n",
      "Decoded sentence: Mangez-le.\n",
      "\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Lève-toi !\n",
      "\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Vas-y maintenant.\n",
      "\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Aha !\n",
      "\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Pigé ?\n",
      "\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Montez.\n",
      "\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serrez-moi dans vos bras !\n",
      "\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombée.\n",
      "\n",
      "Input sentence: I fled.\n",
      "Decoded sentence: J'ai fui.\n",
      "\n",
      "Input sentence: I knit.\n",
      "Decoded sentence: Je tricote.\n",
      "\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je sais.\n",
      "\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis parti.\n",
      "\n",
      "Input sentence: I lied.\n",
      "Decoded sentence: J'ai menti.\n",
      "\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: J'ai perdu.\n",
      "\n",
      "Input sentence: I paid.\n",
      "Decoded sentence: Je payais.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded = []\n",
    "for seq_index in range(0,100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "#     print(\"-\")\n",
    "    decoded.append(decoded_sentence)\n",
    "    #Only print out sentences that we have not seen before\n",
    "    if(decoded[seq_index] != decoded[seq_index-1]):\n",
    "        print(\"Input sentence:\", input_texts[seq_index])\n",
    "        print(\"Decoded sentence:\", decoded_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I went through these outputs, using google translate from French to English to test how good they actually are, and found that most of them are pretty good. There are a few that the meaning gets slightly altered, assuming google translate keeps the meaning the same. For example, \"I won!\" get translated French and using google translate we translate it back to \"I took it away!\". This is not a perfect translation, however the meaning is still not too far off. In the context of \"I won the trophy\" a translation of \"I took [the trophy] away!\" is not perfect but almost conveys the same meaning. Additionally, the French translation from \"I see.\" gets translated back to \"I understand\". In this case, this is a perfectly good translation but not necessarily the one I would have assumed the model would make. I would have assumed the more common translation using the context of \"I see the bird\" would be conveyed. This is obviously not a problem but I just found it interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: I like to swim.\n",
      "Decoded sentence: J'aime celles-ci.\n",
      "\n",
      "Input sentence: I like to talk.\n",
      "Decoded sentence: J'aime ceux-ci.\n",
      "\n",
      "Input sentence: I like turtles.\n",
      "Decoded sentence: J'aime les sormège.\n",
      "\n",
      "Input sentence: I like walking.\n",
      "Decoded sentence: J'aime les sommbols.\n",
      "\n",
      "Input sentence: I like working.\n",
      "Decoded sentence: J'aime les trains.\n",
      "\n",
      "Input sentence: I lit the fire.\n",
      "Decoded sentence: Je l'ai apprécié.\n",
      "\n",
      "Input sentence: I lit the oven.\n",
      "Decoded sentence: Je l'apprécie.\n",
      "\n",
      "Input sentence: I live in town.\n",
      "Decoded sentence: Je travaille seule.\n",
      "\n",
      "Input sentence: I live upstate.\n",
      "Decoded sentence: Je t'aimis.\n",
      "\n",
      "Input sentence: I lost control.\n",
      "Decoded sentence: Je perdis la chant.\n",
      "\n",
      "Input sentence: I lost my keys.\n",
      "Decoded sentence: Je perdis la clé.\n",
      "\n",
      "Input sentence: I lost the bet.\n",
      "Decoded sentence: J'ai perdu courage.\n",
      "\n",
      "Input sentence: I love animals.\n",
      "Decoded sentence: J'adore les livre.\n",
      "\n",
      "Input sentence: I love bananas.\n",
      "Decoded sentence: J'adore les livres.\n",
      "\n",
      "Input sentence: I love cookies.\n",
      "Decoded sentence: J'adore les bonnous.\n",
      "\n",
      "Input sentence: I love cooking.\n",
      "Decoded sentence: J'adore le grançon.\n",
      "\n",
      "Input sentence: I love dessert.\n",
      "Decoded sentence: J'adore les plansaire.\n",
      "\n",
      "Input sentence: I love flowers.\n",
      "Decoded sentence: J'adore les chevaux.\n",
      "\n",
      "Input sentence: I love it here.\n",
      "Decoded sentence: J'adore le créache.\n",
      "\n",
      "Input sentence: I love lasagna.\n",
      "Decoded sentence: J'adore les chameaux.\n",
      "\n",
      "Input sentence: I love my home.\n",
      "Decoded sentence: J'aime ma maman.\n",
      "\n",
      "Input sentence: I love my kids.\n",
      "Decoded sentence: J'adore mon boulot.\n",
      "\n",
      "Input sentence: I love my life.\n",
      "Decoded sentence: J'adore l'éfaxt.\n",
      "\n",
      "Input sentence: I love my work.\n",
      "Decoded sentence: J'aime mon boulot.\n",
      "\n",
      "Input sentence: I love parties.\n",
      "Decoded sentence: J'adore le printemps.\n",
      "\n",
      "Input sentence: I love puzzles.\n",
      "Decoded sentence: J'adore la poésient.\n",
      "\n",
      "Input sentence: I love reading.\n",
      "Decoded sentence: J'adére les biège.\n",
      "\n",
      "Input sentence: I love secrets.\n",
      "Decoded sentence: J'aime les volage.\n",
      "\n",
      "Input sentence: I love sunsets.\n",
      "Decoded sentence: J'adore les plans.\n",
      "\n",
      "Input sentence: I love the sun.\n",
      "Decoded sentence: J'adore les livar.\n",
      "\n",
      "Input sentence: I love to cook.\n",
      "Decoded sentence: J'adore le cantraça.\n",
      "\n",
      "Input sentence: I love to fish.\n",
      "Decoded sentence: J'adore le cain.\n",
      "\n",
      "Input sentence: I love to read.\n",
      "Decoded sentence: J'aime les bonncots.\n",
      "\n",
      "Input sentence: I love to swim.\n",
      "Decoded sentence: J'adore les chavaux.\n",
      "\n",
      "Input sentence: I love winning.\n",
      "Decoded sentence: J'adore les films.\n",
      "\n",
      "Input sentence: I love you all.\n",
      "Decoded sentence: Je t'aime.\n",
      "\n",
      "Input sentence: I loved French.\n",
      "Decoded sentence: J'adore les folmes.\n",
      "\n",
      "Input sentence: I made cookies.\n",
      "Decoded sentence: J'ai préparé du café.\n",
      "\n",
      "Input sentence: I made muffins.\n",
      "Decoded sentence: Je l'ai fait partir.\n",
      "\n",
      "Input sentence: I may be wrong.\n",
      "Decoded sentence: Je suis amusié.\n",
      "\n",
      "Input sentence: I mean no harm.\n",
      "Decoded sentence: Je ne me tent pas ma chats.\n",
      "\n",
      "Input sentence: I met a friend.\n",
      "Decoded sentence: Je ne pris bon.\n",
      "\n",
      "Input sentence: I met him once.\n",
      "Decoded sentence: Je les ai brûlées.\n",
      "\n",
      "Input sentence: I miss college.\n",
      "Decoded sentence: Je suis très rapide.\n",
      "\n",
      "Input sentence: I miss my wife.\n",
      "Decoded sentence: Mon comme que ça.\n",
      "\n",
      "Input sentence: I missed a lot.\n",
      "Decoded sentence: Ça mellais bien.\n",
      "\n",
      "Input sentence: I must buy one.\n",
      "Decoded sentence: Je dois partir maintenant.\n",
      "\n",
      "Input sentence: I must decline.\n",
      "Decoded sentence: J'ai été drogué.\n",
      "\n",
      "Input sentence: I must protest.\n",
      "Decoded sentence: Je dois sort.\n",
      "\n",
      "Input sentence: I must see you.\n",
      "Decoded sentence: Je dois partir.\n",
      "\n",
      "Input sentence: I need a break.\n",
      "Decoded sentence: J'ai besoin d'un bain.\n",
      "\n",
      "Input sentence: I need friends.\n",
      "Decoded sentence: Je dois partir de la muinque.\n",
      "\n",
      "Input sentence: I need it ASAP.\n",
      "Decoded sentence: Je dois partir.\n",
      "\n",
      "Input sentence: I need support.\n",
      "Decoded sentence: J'ai besoin de suci.\n",
      "\n",
      "Input sentence: I need to know.\n",
      "Decoded sentence: Je dois partir.\n",
      "\n",
      "Input sentence: I need you now.\n",
      "Decoded sentence: Je nous en vai.\n",
      "\n",
      "Input sentence: I needed money.\n",
      "Decoded sentence: Il m'en faut des y aleus.\n",
      "\n",
      "Input sentence: I never go out.\n",
      "Decoded sentence: Je ne merre jasais.\n",
      "\n",
      "Input sentence: I noticed that.\n",
      "Decoded sentence: Je l'ai conteré.\n",
      "\n",
      "Input sentence: I often hiccup.\n",
      "Decoded sentence: Je skie souvent.\n",
      "\n",
      "Input sentence: I often travel.\n",
      "Decoded sentence: Je lis le baos.\n",
      "\n",
      "Input sentence: I owe him $100.\n",
      "Decoded sentence: J'ai été droguée.\n",
      "\n",
      "Input sentence: I own this car.\n",
      "Decoded sentence: Je ne pris da malconerai.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decoded = []\n",
    "for seq_index in range(9900,10000):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index : seq_index +1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    decoded.append(decoded_sentence)\n",
    "    #Only print out sentences that we have not seen before\n",
    "    if(decoded[seq_index-9900] != decoded[seq_index-9901]):\n",
    "        print(\"Input sentence:\", input_texts[seq_index])\n",
    "        print(\"Decoded sentence:\", decoded_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I would expect, the model struggles more with the longer sentences. I did not go through every output but I found most of them were slightly off in terms of the meaning. For example, \"I love my kids\" was translated in French and using google translate to translate back into english we get \"I love my job\". clearly it is not the same meaning but in a way, dealing with kids is sort of like having a job so we can see that the meaning is almost there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_history(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots, we see that the validation accuracy hits a hard limit of about .88 even as the training accuracy improves to nearly 1. Interestly, the validitation loss increase after about 10 epochs as the training loss decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final thoughts\n",
    "As someone new to deep learning, NLP, and as such machine translation, this was an incredibly interesting process for me. This class has taught me so far that a lot of the things that I thought of as \"magic\" before can be done fairly easily using python and its libraries. Google translate was always a mystery to me but I can see how it can be done now. Obviously, the model I made in this notebook is so much simpler than google translate but I can see how the building blocks to create something like google translate can be made. Even if I was able to use a lot more training data and I was able to train the model longer, I can assume that even that would be enough to drastically improve this translation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
